# Audio + Video Analysis

## Authors
Sam Tarakajian for NYU IDM

DM-GY 6063

@starakaj

## Essential Questions
- How do computers encode audio and video data?
- What are the salient features of audio and video?
- How can we detect and analyze those features?
- What are some creative applications?

## Introduction
Simply put, sound is just vibrations in the air, and light is just an electromagnetic vibration. However, human beings and other living organisms have evolved complex biomechanical systems for detecting these vibrations, and equally complex neural machinery for analyzing them. Microphones and cameras do the work of ears and eyes, recording sound and light for later reproduction. In this class, we want to do the challenging work of figuring out what is meaningful in a sound or video recording.

When we talk about the meaning of a data stream, we're often talking about features, and usually grouping those features into hierarchical levels. We might talk about low level features like color or loudness, in addition to high level features like emotion or genre. We'll look at techniques for extracting low and high level features, and investigate some creative applications.

### Target Audience / Prerequisite & Pre-Assessment
This module is part of DM-GY 6063, _Programming is the Art of the Possible_. This is a second semester creative coding course, designed for students who have a strong JavaScript foundation.

### Outcomes & Goals
* In this class we'll be working with audio and video recordings, as well as live audio and video streams. We'll look at how computers represent this data, and we'll explore some software libraries for analyzing that data.
* Students will walk away with a deeper understanding of how audio and video analysis works. They'll take away some useful tools for performing that analysis, and they'll have exposure to creative techniques for working with extracted features.

### Pacing / Duration
TBD

## Materials Needed
TBD, but certainly a laptop and a browser. Other helpful software:
- Meyda.js
- Synopsis
- Max/MSP
- Freesound/Essentia

### Exercises To Do Before Class
TBD. Maybe a reading about Luke's work with SPL measurements? Maybe something from sonic weapons?

### Vocabulary (example)
* Feature - (find a good definition of this, it's not trivial).
* Envelope - The slow-moving amplitude of a sound, related to its loudness. Commonly divided into Attack, Decay, Sustain, Release portions for modeling instruments.
* Optical Flow - A matrix describing the flow of pixels between images (needs a better definitions).
* Spectrum - A power-histogram representation of the frequency content of a signal.
* Discrete Fourier Transform - A function for transforming a series of samples from a time domain representation to a frequency domain representation.
* Harmonic - Sounds whose spectral content is mostly grouped into bands, the center frequencies of which are whole number multiples of each other.
* Face Tracking - Automatically estimating the position of a face in an image or video, possibly including its size and orientation.

## Exercise Descriptions
TBD

## Student Reflections, Takeaways & Next Steps
TBD

## Post Session

### References
TBD

### Implementation Guidance & Teaching Reflection  
TBD

***With thanks and acknowledgement, this is based on the template provided by [Eyebeam](https://github.com/eyebeam/curriculum/blob/master/TEMPLATE.md)***